{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_generation_Acknowledgement_2A.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "DLQxGXaWU3YV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['Acknowledgement']\n",
        "\n",
        "# Join all the sentences together and extract the unique characters from the combined sentences\n",
        "chars = set(''.join(text))\n",
        "\n",
        "# Creating a dictionary that maps integers to the characters\n",
        "int2char = dict(enumerate(chars))\n",
        "\n",
        "# Creating another dictionary that maps characters to integers\n",
        "char2int = {char: ind for ind, char in int2char.items()}"
      ],
      "metadata": {
        "id": "MYXs5eZhVwmH"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int2char.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGCCygIT8R_8",
        "outputId": "6dccd413-f408-4e77-dcc0-3aa30a07e055"
      },
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(0, 'k'), (1, 'e'), (2, 'g'), (3, 'm'), (4, 'o'), (5, 'l'), (6, 't'), (7, 'A'), (8, 'w'), (9, 'n'), (10, 'd'), (11, 'c')])"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(int2char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OYEZbQ27yKZ",
        "outputId": "aa9e0855-7f84-4d27-c839-6757c88aba89"
      },
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'k', 1: 'e', 2: 'g', 3: 'm', 4: 'o', 5: 'l', 6: 't', 7: 'A', 8: 'w', 9: 'n', 10: 'd', 11: 'c'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(char2int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvore-SJxQ6L",
        "outputId": "0a48da5f-d471-4705-9e77-ca42aa006d61"
      },
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'k': 0, 'e': 1, 'g': 2, 'm': 3, 'o': 4, 'l': 5, 't': 6, 'A': 7, 'w': 8, 'n': 9, 'd': 10, 'c': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(char2int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAILHRwaBNWt",
        "outputId": "78db4ad0-d7b3-4cb5-c20f-a6f0a1a5c154"
      },
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = len(max(text, key=len))\n"
      ],
      "metadata": {
        "id": "IgKsSY1Bybkt"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Creating the  lists that will hold our input and target sequences\n",
        "input_seq = []\n",
        "target_seq = []\n",
        "\n",
        "for i in range(len(text)):\n",
        "    # Remove the  last character for input sequence\n",
        "  input_seq.append(text[i][:-1])\n",
        "    \n",
        "    # Remove the first character for target sequence\n",
        "  target_seq.append(text[i][1:])\n",
        "\n",
        "  print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eR9RLPhxXnO",
        "outputId": "016f7bbe-5601-4e39-b987-6ae57876ad95"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: Acknowledgemen\n",
            "Target Sequence: cknowledgement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
        "    print(input_seq[i])\n",
        "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
        "    print(target_seq[i])"
      ],
      "metadata": {
        "id": "f-UDWGRwxztt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619b1395-56bb-4b41-fb86-7011a85b58f9"
      },
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 11, 0, 9, 4, 8, 5, 1, 10, 2, 1, 3, 1, 9]\n",
            "[11, 0, 9, 4, 8, 5, 1, 10, 2, 1, 3, 1, 9, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shWqQ36Rx5Q6",
        "outputId": "96a85d18-be82-450f-aa01-7d43959f8417"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: [7, 11, 0, 9, 4, 8, 5, 1, 10, 2, 1, 3, 1, 9]\n",
            "Target Sequence: [11, 0, 9, 4, 8, 5, 1, 10, 2, 1, 3, 1, 9, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_size = len(char2int)    ##########   Dictionary size :- The number of unique characters that we have in our text \n",
        "print(dict_size)\n",
        "seq_len = maxlen - 1         ##########   The length of the sequences that we are feeding into the model \n",
        "print(seq_len)\n",
        "batch_size = len(text)       ##########   The number of sentences that we defined and are going to feed into the model as a batch\n",
        "print(batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGYyMD_2ggyT",
        "outputId": "c4928003-077f-45b2-a7f1-eaa582f729e7"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "14\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_size = len(char2int)\n",
        "seq_len = maxlen - 1\n",
        "batch_size = len(text)\n",
        "\n",
        "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
        "    #######   Creating a multi-dimensional array of zeros with the desired output shape\n",
        "\n",
        "    \n",
        "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
        "    print(features)\n",
        "    \n",
        "    ######### Replacing the 0 at the relevant character index with a 1 to represent that character\n",
        "\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        for u in range(seq_len):\n",
        "            features[i, u, sequence[i][u]] = 1\n",
        "    return features"
      ],
      "metadata": {
        "id": "mBDmP7UGyAQp"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O0iu4wAFfvkA"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHHmoskyyhhJ",
        "outputId": "0e7c6b24-eb5c-400c-e7f9-225ce714ddd3"
      },
      "execution_count": 404,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2eLH_0Byu3B",
        "outputId": "b5131a4b-70b1-495f-9ee3-121d99fc9bcb"
      },
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "######  we can now move the data from NumPy arrays to PyTorch's very own data structure that is  Torch Tensors.\n",
        "\n",
        "input_seq = torch.from_numpy(input_seq)  \n",
        "target_seq = torch.Tensor(target_seq)"
      ],
      "metadata": {
        "id": "NSOYWPHGy22a"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it will return False\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "###  If we have a GPU available, we will set our device to GPU \n",
        "###  but here since training data is so small so i am using only CPU here\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHMsu6g6y7yg",
        "outputId": "8124b4b3-19e4-4d82-de2b-13ef28d9cf3f"
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, CPU used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        #### Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #### Defining the layers\n",
        "        ###  RNN Layer\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        ### Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):   ######## defining the forward pass function\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        ####### Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        #####  Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        ###### Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):    #######  This basically creates a tensor of zeros in the shape of our hidden states.\n",
        "        ## This method generates the first hidden state of zeros which we will use in the forward pass\n",
        "        ## We will send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "Fb_XiGE8zBzO"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=15, n_layers=1)\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model.to(device)\n",
        "\n",
        "#### Defining the  hyperparameters\n",
        "\n",
        "n_epochs =1000  ## number of epochs \n",
        "lr=0.002         ## learning rate \n",
        "\n",
        "\n",
        "###### Define Loss, Optimizer\n",
        "############################################### Adam optimizer #####################################\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  ##### we are using here Adam optimizer \n"
      ],
      "metadata": {
        "id": "0wYZfT-UzKbB"
      },
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Run\n",
        "all_losses = [] ##### initializing list of all_losses to maintain all losses inside it .\n",
        "ep = []         #### initializing list ep to maintain all the corresponding epochs \n",
        "##total_loss = 0 # Reset every plot_every iters\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    optimizer.zero_grad() ######  Clears existing gradients from previous epoch\n",
        "    input_seq.to(device)\n",
        "    output, hidden = model(input_seq)\n",
        "    loss = criterion(output, target_seq.view(-1).long())\n",
        "    loss.backward()     ######## Does backpropagation and calculates gradients\n",
        "    optimizer.step()    ######### Updates the weights accordingly\n",
        "    \n",
        "    \n",
        "    \n",
        "    if epoch%10 == 0:\n",
        "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
        "        ep.append(epoch)\n",
        "        all_losses.append(loss)\n"
      ],
      "metadata": {
        "id": "AGkOwJHizOn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d121570-c409-4170-dcff-2e50803a6075"
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/1000............. Loss: 2.4069\n",
            "Epoch: 20/1000............. Loss: 2.2912\n",
            "Epoch: 30/1000............. Loss: 2.1595\n",
            "Epoch: 40/1000............. Loss: 1.9906\n",
            "Epoch: 50/1000............. Loss: 1.7830\n",
            "Epoch: 60/1000............. Loss: 1.5733\n",
            "Epoch: 70/1000............. Loss: 1.3738\n",
            "Epoch: 80/1000............. Loss: 1.1856\n",
            "Epoch: 90/1000............. Loss: 1.0118\n",
            "Epoch: 100/1000............. Loss: 0.8572\n",
            "Epoch: 110/1000............. Loss: 0.7244\n",
            "Epoch: 120/1000............. Loss: 0.6123\n",
            "Epoch: 130/1000............. Loss: 0.5184\n",
            "Epoch: 140/1000............. Loss: 0.4399\n",
            "Epoch: 150/1000............. Loss: 0.3744\n",
            "Epoch: 160/1000............. Loss: 0.3201\n",
            "Epoch: 170/1000............. Loss: 0.2752\n",
            "Epoch: 180/1000............. Loss: 0.2382\n",
            "Epoch: 190/1000............. Loss: 0.2076\n",
            "Epoch: 200/1000............. Loss: 0.1823\n",
            "Epoch: 210/1000............. Loss: 0.1613\n",
            "Epoch: 220/1000............. Loss: 0.1436\n",
            "Epoch: 230/1000............. Loss: 0.1287\n",
            "Epoch: 240/1000............. Loss: 0.1161\n",
            "Epoch: 250/1000............. Loss: 0.1053\n",
            "Epoch: 260/1000............. Loss: 0.0959\n",
            "Epoch: 270/1000............. Loss: 0.0878\n",
            "Epoch: 280/1000............. Loss: 0.0808\n",
            "Epoch: 290/1000............. Loss: 0.0745\n",
            "Epoch: 300/1000............. Loss: 0.0691\n",
            "Epoch: 310/1000............. Loss: 0.0642\n",
            "Epoch: 320/1000............. Loss: 0.0598\n",
            "Epoch: 330/1000............. Loss: 0.0559\n",
            "Epoch: 340/1000............. Loss: 0.0524\n",
            "Epoch: 350/1000............. Loss: 0.0493\n",
            "Epoch: 360/1000............. Loss: 0.0464\n",
            "Epoch: 370/1000............. Loss: 0.0438\n",
            "Epoch: 380/1000............. Loss: 0.0414\n",
            "Epoch: 390/1000............. Loss: 0.0392\n",
            "Epoch: 400/1000............. Loss: 0.0372\n",
            "Epoch: 410/1000............. Loss: 0.0353\n",
            "Epoch: 420/1000............. Loss: 0.0336\n",
            "Epoch: 430/1000............. Loss: 0.0321\n",
            "Epoch: 440/1000............. Loss: 0.0306\n",
            "Epoch: 450/1000............. Loss: 0.0292\n",
            "Epoch: 460/1000............. Loss: 0.0280\n",
            "Epoch: 470/1000............. Loss: 0.0268\n",
            "Epoch: 480/1000............. Loss: 0.0257\n",
            "Epoch: 490/1000............. Loss: 0.0247\n",
            "Epoch: 500/1000............. Loss: 0.0237\n",
            "Epoch: 510/1000............. Loss: 0.0228\n",
            "Epoch: 520/1000............. Loss: 0.0219\n",
            "Epoch: 530/1000............. Loss: 0.0211\n",
            "Epoch: 540/1000............. Loss: 0.0204\n",
            "Epoch: 550/1000............. Loss: 0.0197\n",
            "Epoch: 560/1000............. Loss: 0.0190\n",
            "Epoch: 570/1000............. Loss: 0.0184\n",
            "Epoch: 580/1000............. Loss: 0.0178\n",
            "Epoch: 590/1000............. Loss: 0.0172\n",
            "Epoch: 600/1000............. Loss: 0.0166\n",
            "Epoch: 610/1000............. Loss: 0.0161\n",
            "Epoch: 620/1000............. Loss: 0.0156\n",
            "Epoch: 630/1000............. Loss: 0.0152\n",
            "Epoch: 640/1000............. Loss: 0.0147\n",
            "Epoch: 650/1000............. Loss: 0.0143\n",
            "Epoch: 660/1000............. Loss: 0.0139\n",
            "Epoch: 670/1000............. Loss: 0.0135\n",
            "Epoch: 680/1000............. Loss: 0.0131\n",
            "Epoch: 690/1000............. Loss: 0.0128\n",
            "Epoch: 700/1000............. Loss: 0.0124\n",
            "Epoch: 710/1000............. Loss: 0.0121\n",
            "Epoch: 720/1000............. Loss: 0.0118\n",
            "Epoch: 730/1000............. Loss: 0.0115\n",
            "Epoch: 740/1000............. Loss: 0.0112\n",
            "Epoch: 750/1000............. Loss: 0.0109\n",
            "Epoch: 760/1000............. Loss: 0.0106\n",
            "Epoch: 770/1000............. Loss: 0.0104\n",
            "Epoch: 780/1000............. Loss: 0.0101\n",
            "Epoch: 790/1000............. Loss: 0.0099\n",
            "Epoch: 800/1000............. Loss: 0.0097\n",
            "Epoch: 810/1000............. Loss: 0.0095\n",
            "Epoch: 820/1000............. Loss: 0.0092\n",
            "Epoch: 830/1000............. Loss: 0.0090\n",
            "Epoch: 840/1000............. Loss: 0.0088\n",
            "Epoch: 850/1000............. Loss: 0.0086\n",
            "Epoch: 860/1000............. Loss: 0.0085\n",
            "Epoch: 870/1000............. Loss: 0.0083\n",
            "Epoch: 880/1000............. Loss: 0.0081\n",
            "Epoch: 890/1000............. Loss: 0.0079\n",
            "Epoch: 900/1000............. Loss: 0.0078\n",
            "Epoch: 910/1000............. Loss: 0.0076\n",
            "Epoch: 920/1000............. Loss: 0.0075\n",
            "Epoch: 930/1000............. Loss: 0.0073\n",
            "Epoch: 940/1000............. Loss: 0.0072\n",
            "Epoch: 950/1000............. Loss: 0.0070\n",
            "Epoch: 960/1000............. Loss: 0.0069\n",
            "Epoch: 970/1000............. Loss: 0.0068\n",
            "Epoch: 980/1000............. Loss: 0.0067\n",
            "Epoch: 990/1000............. Loss: 0.0065\n",
            "Epoch: 1000/1000............. Loss: 0.0064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes in the model and character as arguments and returns the next character prediction and hidden state\n",
        "def predict(model, character):\n",
        "    ##### One-hot encoding our input to fit into the model\n",
        "    character = np.array([[char2int[c] for c in character]])\n",
        "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
        "    character = torch.from_numpy(character)\n",
        "    character.to(device)\n",
        "    \n",
        "    out, hidden = model(character)\n",
        "\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "    \n",
        "    #### Taking the class with the highest probability score from the output\n",
        "    char_ind = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "    return int2char[char_ind], hidden"
      ],
      "metadata": {
        "id": "iBG_eCTRzh3z"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### This  output function takes the desired output length and input characters as arguments and returns the produced word\n",
        "\n",
        "def output(model, out_len, start):\n",
        "    model.eval() \n",
        "\n",
        "    ##### First off, run through the starting characters\n",
        "    chars = [ch for ch in start]\n",
        "    size = out_len - len(chars)\n",
        "    \n",
        "    ##### Now pass in the previous characters and get a new one\n",
        "    for i in range(size):\n",
        "        char, h = predict(model, chars)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "SPmooAN4zUcp"
      },
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output(model, 15, 'A')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F2Hyg3F4zZA5",
        "outputId": "b194c430-28a9-4c51-dd10-83c1a7e711e9"
      },
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Acknowledgement'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "9UmQNkn_DlRU"
      },
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plt.plot(all_losses, ep, marker='o')\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.show()."
      ],
      "metadata": {
        "id": "U3PD-7_kFHJP"
      },
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor1 = torch.tensor(all_losses,requires_grad=True)\n",
        "tensor1 = tensor1.detach().numpy()\n"
      ],
      "metadata": {
        "id": "rkIDAUJ2JwMG"
      },
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(ep,tensor1)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "VB4p4XyaDSSw",
        "outputId": "072ecede-572a-4b6e-b4bf-37ed138f6603"
      },
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output(model , 8, 'e')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "pW__G1htzmTC",
        "outputId": "cf4c011f-b484-4411-bb77-af5148da58fc"
      },
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
            "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ecknowle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9t8bbjQjmj0w"
      },
      "execution_count": 418,
      "outputs": []
    }
  ]
}